<!DOCTYPE html><html lang="en"><head>
  <meta charset="utf-8">
  <title>Paper reading - ADADELTA AN ADAPTIVE LEARNING RATE METHOD</title>
  <base href="/">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="fb:app_id" content="1678943848891569">

  <link rel="icon" href="/favicon.ico">
  <meta name="description" content="Author: Liam, Date: Jun 13, 2015

The aim of many machine learning methods is to update a set of parameters $x$ in order to optimize an objective function $f(x)$.
This often involves some iterative procedure which applies changes to the parameters, $\Delta{x}$ at each iteration of the algorithm.
">
  <meta property="og:type" content="article">
  <meta property="og:image" content="https://www.leliam.com/assets/2015061300.png">
  <meta property="og:image:url" content="https://www.leliam.com/assets/2015061300.png">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-47309606-3"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async=""></script>
  <!-- <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-47309606-3');
  </script> -->
  <link rel="manifest" href="manifest.json">
  <meta name="theme-color" content="#1976d2">
<link rel="stylesheet" href="styles.22f73f6901a53af68e2a.css"><style ng-transition="leliam">h1[_ngcontent-sc0] {
  font-size: 1.2em;
  color: #999;
  margin-bottom: 0;
}
h2[_ngcontent-sc0] {
  font-size: 2em;
  margin-top: 0;
  padding-top: 0;
}
nav[_ngcontent-sc0]   a[_ngcontent-sc0] {
  padding: 5px 10px;
  text-decoration: none;
  margin-top: 10px;
  display: inline-block;
  background-color: #eee;
  border-radius: 4px;
}
nav[_ngcontent-sc0]   a[_ngcontent-sc0]:visited, a[_ngcontent-sc0]:link {
  color: #607D8B;
}
nav[_ngcontent-sc0]   a[_ngcontent-sc0]:hover {
  color: #039be5;
  background-color: #CFD8DC;
}
nav[_ngcontent-sc0]   a.active[_ngcontent-sc0] {
  color: #039be5;
}
body[_ngcontent-sc0] {
  height: 100%;
}</style><style ng-transition="leliam">.toolbar-fill-remaining-space[_ngcontent-sc2] {
  
  -ms-flex: 1 1 auto;
      flex: 1 1 auto;
}
a[_ngcontent-sc2] {
  text-decoration: none;
}</style><style ng-transition="leliam"></style><style ng-transition="leliam">@media screen and (-ms-high-contrast:active){.mat-toolbar{outline:solid 1px}}.mat-toolbar-row,.mat-toolbar-single-row{display:flex;box-sizing:border-box;padding:0 16px;width:100%;flex-direction:row;align-items:center;white-space:nowrap}.mat-toolbar-multiple-rows{display:flex;box-sizing:border-box;flex-direction:column;width:100%}.mat-toolbar-multiple-rows{min-height:64px}.mat-toolbar-row,.mat-toolbar-single-row{height:64px}@media (max-width:599px){.mat-toolbar-multiple-rows{min-height:56px}.mat-toolbar-row,.mat-toolbar-single-row{height:56px}}</style><style ng-transition="leliam">.mat-menu-panel{min-width:112px;max-width:280px;overflow:auto;-webkit-overflow-scrolling:touch;max-height:calc(100vh - 48px);border-radius:2px;outline:0}.mat-menu-panel:not([class*=mat-elevation-z]){box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12)}@media screen and (-ms-high-contrast:active){.mat-menu-panel{outline:solid 1px}}.mat-menu-content{padding-top:8px;padding-bottom:8px}.mat-menu-item{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:pointer;outline:0;border:none;-webkit-tap-highlight-color:transparent;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;display:block;line-height:48px;height:48px;padding:0 16px;text-align:left;text-decoration:none;position:relative}.mat-menu-item[disabled]{cursor:default}[dir=rtl] .mat-menu-item{text-align:right}.mat-menu-item .mat-icon{margin-right:16px;vertical-align:middle}.mat-menu-item .mat-icon svg{vertical-align:top}[dir=rtl] .mat-menu-item .mat-icon{margin-left:16px;margin-right:0}.mat-menu-item-submenu-trigger{padding-right:32px}.mat-menu-item-submenu-trigger::after{width:0;height:0;border-style:solid;border-width:5px 0 5px 5px;border-color:transparent transparent transparent currentColor;content:'';display:inline-block;position:absolute;top:50%;right:16px;transform:translateY(-50%)}[dir=rtl] .mat-menu-item-submenu-trigger{padding-right:16px;padding-left:32px}[dir=rtl] .mat-menu-item-submenu-trigger::after{right:auto;left:16px;transform:rotateY(180deg) translateY(-50%)}.mat-menu-panel.ng-animating .mat-menu-item-submenu-trigger{pointer-events:none}button.mat-menu-item{width:100%}.mat-menu-ripple{top:0;left:0;right:0;bottom:0;position:absolute;pointer-events:none}</style><style ng-transition="leliam">.mat-button,.mat-flat-button,.mat-icon-button,.mat-stroked-button{box-sizing:border-box;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:pointer;outline:0;border:none;-webkit-tap-highlight-color:transparent;display:inline-block;white-space:nowrap;text-decoration:none;vertical-align:baseline;text-align:center;margin:0;min-width:88px;line-height:36px;padding:0 16px;border-radius:2px;overflow:visible}.mat-button[disabled],.mat-flat-button[disabled],.mat-icon-button[disabled],.mat-stroked-button[disabled]{cursor:default}.mat-button.cdk-keyboard-focused .mat-button-focus-overlay,.mat-button.cdk-program-focused .mat-button-focus-overlay,.mat-flat-button.cdk-keyboard-focused .mat-button-focus-overlay,.mat-flat-button.cdk-program-focused .mat-button-focus-overlay,.mat-icon-button.cdk-keyboard-focused .mat-button-focus-overlay,.mat-icon-button.cdk-program-focused .mat-button-focus-overlay,.mat-stroked-button.cdk-keyboard-focused .mat-button-focus-overlay,.mat-stroked-button.cdk-program-focused .mat-button-focus-overlay{opacity:1}.mat-button::-moz-focus-inner,.mat-flat-button::-moz-focus-inner,.mat-icon-button::-moz-focus-inner,.mat-stroked-button::-moz-focus-inner{border:0}.mat-button .mat-button-focus-overlay,.mat-icon-button .mat-button-focus-overlay{transition:none;opacity:0}.mat-button:hover .mat-button-focus-overlay,.mat-stroked-button:hover .mat-button-focus-overlay{opacity:1}.mat-raised-button{box-sizing:border-box;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:pointer;outline:0;border:none;-webkit-tap-highlight-color:transparent;display:inline-block;white-space:nowrap;text-decoration:none;vertical-align:baseline;text-align:center;margin:0;min-width:88px;line-height:36px;padding:0 16px;border-radius:2px;overflow:visible;transform:translate3d(0,0,0);transition:background .4s cubic-bezier(.25,.8,.25,1),box-shadow 280ms cubic-bezier(.4,0,.2,1)}.mat-raised-button[disabled]{cursor:default}.mat-raised-button.cdk-keyboard-focused .mat-button-focus-overlay,.mat-raised-button.cdk-program-focused .mat-button-focus-overlay{opacity:1}.mat-raised-button::-moz-focus-inner{border:0}.mat-raised-button:not([class*=mat-elevation-z]){box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12)}._mat-animation-noopable.mat-raised-button{transition:none;animation:none}.mat-raised-button:not([disabled]):active:not([class*=mat-elevation-z]){box-shadow:0 5px 5px -3px rgba(0,0,0,.2),0 8px 10px 1px rgba(0,0,0,.14),0 3px 14px 2px rgba(0,0,0,.12)}.mat-raised-button[disabled]{box-shadow:none}.mat-stroked-button{border:1px solid currentColor;padding:0 15px;line-height:34px}.mat-stroked-button:not([class*=mat-elevation-z]){box-shadow:0 0 0 0 rgba(0,0,0,.2),0 0 0 0 rgba(0,0,0,.14),0 0 0 0 rgba(0,0,0,.12)}.mat-flat-button:not([class*=mat-elevation-z]){box-shadow:0 0 0 0 rgba(0,0,0,.2),0 0 0 0 rgba(0,0,0,.14),0 0 0 0 rgba(0,0,0,.12)}.mat-fab{box-sizing:border-box;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:pointer;outline:0;border:none;-webkit-tap-highlight-color:transparent;display:inline-block;white-space:nowrap;text-decoration:none;vertical-align:baseline;text-align:center;margin:0;min-width:88px;line-height:36px;padding:0 16px;border-radius:2px;overflow:visible;transform:translate3d(0,0,0);transition:background .4s cubic-bezier(.25,.8,.25,1),box-shadow 280ms cubic-bezier(.4,0,.2,1);min-width:0;border-radius:50%;width:56px;height:56px;padding:0;flex-shrink:0}.mat-fab[disabled]{cursor:default}.mat-fab.cdk-keyboard-focused .mat-button-focus-overlay,.mat-fab.cdk-program-focused .mat-button-focus-overlay{opacity:1}.mat-fab::-moz-focus-inner{border:0}.mat-fab:not([class*=mat-elevation-z]){box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12)}._mat-animation-noopable.mat-fab{transition:none;animation:none}.mat-fab:not([disabled]):active:not([class*=mat-elevation-z]){box-shadow:0 5px 5px -3px rgba(0,0,0,.2),0 8px 10px 1px rgba(0,0,0,.14),0 3px 14px 2px rgba(0,0,0,.12)}.mat-fab[disabled]{box-shadow:none}.mat-fab:not([class*=mat-elevation-z]){box-shadow:0 3px 5px -1px rgba(0,0,0,.2),0 6px 10px 0 rgba(0,0,0,.14),0 1px 18px 0 rgba(0,0,0,.12)}.mat-fab:not([disabled]):active:not([class*=mat-elevation-z]){box-shadow:0 7px 8px -4px rgba(0,0,0,.2),0 12px 17px 2px rgba(0,0,0,.14),0 5px 22px 4px rgba(0,0,0,.12)}.mat-fab .mat-button-wrapper{padding:16px 0;display:inline-block;line-height:24px}.mat-mini-fab{box-sizing:border-box;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:pointer;outline:0;border:none;-webkit-tap-highlight-color:transparent;display:inline-block;white-space:nowrap;text-decoration:none;vertical-align:baseline;text-align:center;margin:0;min-width:88px;line-height:36px;padding:0 16px;border-radius:2px;overflow:visible;transform:translate3d(0,0,0);transition:background .4s cubic-bezier(.25,.8,.25,1),box-shadow 280ms cubic-bezier(.4,0,.2,1);min-width:0;border-radius:50%;width:40px;height:40px;padding:0;flex-shrink:0}.mat-mini-fab[disabled]{cursor:default}.mat-mini-fab.cdk-keyboard-focused .mat-button-focus-overlay,.mat-mini-fab.cdk-program-focused .mat-button-focus-overlay{opacity:1}.mat-mini-fab::-moz-focus-inner{border:0}.mat-mini-fab:not([class*=mat-elevation-z]){box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12)}._mat-animation-noopable.mat-mini-fab{transition:none;animation:none}.mat-mini-fab:not([disabled]):active:not([class*=mat-elevation-z]){box-shadow:0 5px 5px -3px rgba(0,0,0,.2),0 8px 10px 1px rgba(0,0,0,.14),0 3px 14px 2px rgba(0,0,0,.12)}.mat-mini-fab[disabled]{box-shadow:none}.mat-mini-fab:not([class*=mat-elevation-z]){box-shadow:0 3px 5px -1px rgba(0,0,0,.2),0 6px 10px 0 rgba(0,0,0,.14),0 1px 18px 0 rgba(0,0,0,.12)}.mat-mini-fab:not([disabled]):active:not([class*=mat-elevation-z]){box-shadow:0 7px 8px -4px rgba(0,0,0,.2),0 12px 17px 2px rgba(0,0,0,.14),0 5px 22px 4px rgba(0,0,0,.12)}.mat-mini-fab .mat-button-wrapper{padding:8px 0;display:inline-block;line-height:24px}.mat-icon-button{padding:0;min-width:0;width:40px;height:40px;flex-shrink:0;line-height:40px;border-radius:50%}.mat-icon-button .mat-icon,.mat-icon-button i{line-height:24px}.mat-button-focus-overlay,.mat-button-ripple{top:0;left:0;right:0;bottom:0;position:absolute;pointer-events:none;border-radius:inherit}.mat-button-focus-overlay{background-color:rgba(0,0,0,.12);border-radius:inherit;opacity:0;transition:opacity .2s cubic-bezier(.35,0,.25,1),background-color .2s cubic-bezier(.35,0,.25,1)}._mat-animation-noopable .mat-button-focus-overlay{transition:none}@media screen and (-ms-high-contrast:active){.mat-button-focus-overlay{background-color:rgba(255,255,255,.5)}}.mat-button-ripple-round{border-radius:50%;z-index:1}.mat-button .mat-button-wrapper>*,.mat-fab .mat-button-wrapper>*,.mat-flat-button .mat-button-wrapper>*,.mat-icon-button .mat-button-wrapper>*,.mat-mini-fab .mat-button-wrapper>*,.mat-raised-button .mat-button-wrapper>*,.mat-stroked-button .mat-button-wrapper>*{vertical-align:middle}.mat-form-field:not(.mat-form-field-appearance-legacy) .mat-form-field-prefix .mat-icon-button,.mat-form-field:not(.mat-form-field-appearance-legacy) .mat-form-field-suffix .mat-icon-button{display:block;font-size:inherit;width:2.5em;height:2.5em}@media screen and (-ms-high-contrast:active){.mat-button,.mat-fab,.mat-flat-button,.mat-icon-button,.mat-mini-fab,.mat-raised-button{outline:solid 1px}}</style><style ng-transition="leliam">.mat-icon{background-repeat:no-repeat;display:inline-block;fill:currentColor;height:24px;width:24px}.mat-icon.mat-icon-inline{font-size:inherit;height:inherit;line-height:inherit;width:inherit}[dir=rtl] .mat-icon-rtl-mirror{transform:scale(-1,1)}.mat-form-field:not(.mat-form-field-appearance-legacy) .mat-form-field-prefix .mat-icon,.mat-form-field:not(.mat-form-field-appearance-legacy) .mat-form-field-suffix .mat-icon{display:block}.mat-form-field:not(.mat-form-field-appearance-legacy) .mat-form-field-prefix .mat-icon-button .mat-icon,.mat-form-field:not(.mat-form-field-appearance-legacy) .mat-form-field-suffix .mat-icon-button .mat-icon{margin:auto}</style><style ng-transition="leliam">@import url('https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css');
.blogpost-inner[_ngcontent-sc20]     img {
  max-width: 100%
}
.banner-img[_ngcontent-sc20] {
  -o-object-fit: contain;
     object-fit: contain;
}
.td-avatar[_ngcontent-sc20] {
  padding-right: 10px;
}
.avatar-small[_ngcontent-sc20] {
  height: 40px;
  width: 40px;
  border-radius: 50%;
  -ms-flex-negative: 0;
      flex-shrink: 0;
}
a.tag[_ngcontent-sc20] {
  margin-right: 5px;
}
.banner-image-container[_ngcontent-sc20] {
  text-align: center;
}
.banner-image-container[_ngcontent-sc20]   img[_ngcontent-sc20] {
  max-width: 100%;
  max-height: 300px;
}</style><meta property="og:url" content="https://www.leliam.com/blogpost/1f8f35e7-d29f-48a5-8c44-51eb5ed30492"><meta property="og:title" content="Paper reading - ADADELTA AN ADAPTIVE LEARNING RATE METHOD"><meta property="og:description" content="Author: Liam, Date: Jun 13, 2015

The aim of many machine learning methods is to update a set of parameters $x$ in order to optimize an objective function $f(x)$.
This often involves some iterative procedure which applies changes to the parameters, $\Delta{x}$ at each iteration of the algorithm.
"></head>
<body>
  <div id="fb-root"></div>
  <script>(function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = 'https://connect.facebook.net/en_US/sdk.js#xfbml=1&version=v3.0&appId=1678943848891569&autoLogAppEvents=1';
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));</script>
  <app-root _nghost-sc0="" ng-version="6.0.7"><!----><div _ngcontent-sc0="" class="mat-typography"><app-nav _ngcontent-sc0="" _nghost-sc2=""><div _ngcontent-sc2="" class="mat-typography"><!----><div _ngcontent-sc2="" class="ng-star-inserted"><mat-toolbar _ngcontent-sc2="" class="mat-toolbar mat-toolbar-single-row"><mat-menu _ngcontent-sc2="" class="ng-tns-c6-0 ng-star-inserted"><!----></mat-menu><a _ngcontent-sc2="" mat-button="" routerlink="/" class="mat-button _mat-animation-noopable" tabindex="0" aria-disabled="false" href="/"><span class="mat-button-wrapper"><h3 _ngcontent-sc2="">Le Liam</h3></span><div class="mat-button-ripple mat-ripple" matripple=""></div><div class="mat-button-focus-overlay"></div></a><!----><a _ngcontent-sc2="" mat-button="" routerlink="/tags" routerlinkactive="mat-primary" class="mat-button _mat-animation-noopable" tabindex="0" aria-disabled="false" href="/tags"><span class="mat-button-wrapper">Tags</span><div class="mat-button-ripple mat-ripple" matripple=""></div><div class="mat-button-focus-overlay"></div></a><!----><!----><span _ngcontent-sc2="" class="toolbar-fill-remaining-space"></span><!----><!----><button _ngcontent-sc2="" aria-haspopup="true" aria-label="More" color="primary" mat-icon-button="" class="mat-icon-button mat-primary _mat-animation-noopable ng-star-inserted"><span class="mat-button-wrapper"><mat-icon _ngcontent-sc2="" class="mat-icon" role="img" svgicon="more_vert" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fit="" preserveAspectRatio="xMidYMid meet" focusable="false">
<path d="M0 0h24v24H0z" fill="none"></path>
<path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path>
</svg></mat-icon></span><div class="mat-button-ripple mat-ripple mat-button-ripple-round" matripple=""></div><div class="mat-button-focus-overlay"></div></button><!----></mat-toolbar></div><!----></div></app-nav><app-status-bar _ngcontent-sc0="" _nghost-sc3=""><!----></app-status-bar><router-outlet _ngcontent-sc0=""></router-outlet><app-blogpost _nghost-sc20="" class="ng-star-inserted"><!----><!----><!----><div _ngcontent-sc20="" class="ng-star-inserted"><!----><div _ngcontent-sc20="" class="ng-star-inserted"><div _ngcontent-sc20="" class="main-bg" style="padding-bottom:20px"><div _ngcontent-sc20="" class="container"><br _ngcontent-sc20=""><table _ngcontent-sc20=""><tbody _ngcontent-sc20=""><tr _ngcontent-sc20=""><td _ngcontent-sc20="" class="td-avatar" rowspan="2"><div _ngcontent-sc20="" class="avatar-small" style="background-image:url('/assets/32x32_avatar.jpg');background-size:cover;"></div></td><td _ngcontent-sc20="">Liam</td></tr><tr _ngcontent-sc20=""><td _ngcontent-sc20="" style="color:rgba(0,0,0,.54)"><small _ngcontent-sc20="">Jun 13, 2015</small></td></tr></tbody></table><div _ngcontent-sc20="" class="banner-image-container"><!----><img _ngcontent-sc20="" src="/assets/2015061300.png" class="ng-star-inserted"></div><br _ngcontent-sc20=""><h1 _ngcontent-sc20=""> Paper reading - ADADELTA AN ADAPTIVE LEARNING RATE METHOD </h1><div _ngcontent-sc20="" class="blogpost-inner"><p>This <a href="http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf">paper</a> was done by Matthew D. Zeiler while he was an intern at Google.</p>
<h2>Introduction</h2>
<p>The aim of many machine learning methods is to update a set of parameters \(x\) in order to optimize an objective function \(f(x)\).
This often involves some iterative procedure which applies changes to the parameters, \(\Delta{x}\) at each iteration of the algorithm.
Denoting the parameters at the t-th iteration as \(x_t\), this simple update rule becomes:</p>
<p>\[\Delta{x\_t} = - \eta{g\_t}\]</p>
<ul>
<li>\(g_t\) is the gradient of the parameters at the t-th iteration</li>
<li>\(η\) is a learning rate which controls how large of a step to take in the direction of the negative gradient</li>
</ul>
<h2>Purpose</h2>
<p>The idea presented in this paper was derived from ADAGRAD in order to improve upon the two main drawbacks of the method:</p>
<ol>
<li>the continual decay of learning rates throughout training</li>
<li>the need for a manually selected global learning rate.</li>
</ol>
<h2>SGD vs ADAGRAD vs ADADELTA</h2>
<ul>
<li>SGD: \[\Delta{x\_t} = \rho{\Delta{x\_{t-1}}} - \eta{g\_t} \]
<ul>
<li>where \(\rho\) is a constant controlling the decay of the previous parameter updates</li>
</ul>
</li>
<li>ADAGRAD: \[\Delta{x\_t} = -{ {\eta} \over \sqrt{\sum\_{T=1}^t g\_{T}^2} } \]</li>
<li>ADADELTA: \[\Delta{x\_t} = -{ RMS\[\Delta{x}\]\_{t-1} \over RMS\[g\]\_t}g\_t\]
\[RMS[g]\_t = \sqrt{E[g^2]\_t + \epsilon}\]
\[E[g^2]\_t = \rho{E[g^2]\_{t-1} } + (1-\rho)g_{t}^2\]
<ul>
<li>where a constant \(\epsilon\) is added to better condition the denominator</li>
<li>where \(E[g^2]\_t\) is expected value of gradient with power 2 at time t</li>
</ul>
</li>
</ul>
<h2>Result</h2>
<p>Compared with SGD, ADAGRAD and MOMENTUM, normally ADADELTA has a convergence faster and has lower error rate.</p>
<h2>Personal Thought</h2>
<p>Have tried ADADELTA and SGD. Although for each epoch ADADELTA takes longer time to compute, we just have to input (default value)
\(\rho = 0.95\) and \(\epsilon = 1e^{-6}\) then it will learn very well. If use SGD, we have to fine tune the learning
rate and the error rate is often bigger than ADADELTA.</p>
</div><!----><a _ngcontent-sc20="" class="tag mat-stroked-button mat-accent _mat-animation-noopable ng-star-inserted" color="accent" mat-stroked-button="" tabindex="0" aria-disabled="false" href="/tag/machine-learning"><span class="mat-button-wrapper">machine-learning</span><div class="mat-button-ripple mat-ripple" matripple=""></div><div class="mat-button-focus-overlay"></div></a></div></div><div _ngcontent-sc20="" class="container" style="padding-top:20px"><h2 _ngcontent-sc20="">Comments</h2><div _ngcontent-sc20=""></div></div></div></div></app-blogpost></div><!----></app-root>
<script type="text/javascript" src="runtime.47e22179625a669dc75b.js"></script><script type="text/javascript" src="polyfills.f94eba5ea350c574afe6.js"></script><script type="text/javascript" src="main.4e4f89b8dfe1414754dc.js"></script>

<script id="leliam-state" type="application/json">{&q;blogpost-blogpost&q;:{&q;author&q;:{&q;avatar&q;:&q;/assets/32x32_avatar.jpg&q;,&q;name&q;:&q;Liam&q;,&q;tagline&q;:&q;Make people great again!&q;},&q;description&q;:&q;\nThe aim of many machine learning methods is to update a set of parameters $x$ in order to optimize an objective function $f(x)$.\nThis often involves some iterative procedure which applies changes to the parameters, $\\Delta{x}$ at each iteration of the algorithm.\n    &q;,&q;data&q;:&q;\nThis [paper](http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf) was done by Matthew D. Zeiler while he was an intern at Google.\n\n## Introduction\n\nThe aim of many machine learning methods is to update a set of parameters $x$ in order to optimize an objective function $f(x)$.\nThis often involves some iterative procedure which applies changes to the parameters, $\\Delta{x}$ at each iteration of the algorithm.\nDenoting the parameters at the t-th iteration as $x_t$, this simple update rule becomes:\n\n$$\\Delta{x\\_t} = - \\eta{g\\_t}$$\n\n- $g_t$ is the gradient of the parameters at the t-th iteration\n- $η$ is a learning rate which controls how large of a step to take in the direction of the negative gradient\n\n\n## Purpose\n\nThe idea presented in this paper was derived from ADAGRAD in order to improve upon the two main drawbacks of the method:\n\n1. the continual decay of learning rates throughout training\n2. the need for a manually selected global learning rate.\n\n## SGD vs ADAGRAD vs ADADELTA\n\n- SGD: $$\\Delta{x\\_t} = \\rho{\\Delta{x\\_{t-1}}} - \\eta{g\\_t} $$\n  - where $\\rho$ is a constant controlling the decay of the previous parameter updates\n- ADAGRAD: $$\\Delta{x\\_t} = -{ {\\eta} \\over \\sqrt{\\sum\\_{T=1}^t g\\_{T}^2} } $$\n- ADADELTA: $$\\Delta{x\\_t} = -{ RMS\\[\\Delta{x}\\]\\_{t-1} \\over RMS\\[g\\]\\_t}g\\_t$$\n$$RMS[g]\\_t = \\sqrt{E[g^2]\\_t + \\epsilon}$$\n$$E[g^2]\\_t = \\rho{E[g^2]\\_{t-1} } + (1-\\rho)g_{t}^2$$\n  - where a constant $\\epsilon$ is added to better condition the denominator\n  - where $E[g^2]\\_t$ is expected value of gradient with power 2 at time t\n\n## Result\n\nCompared with SGD, ADAGRAD and MOMENTUM, normally ADADELTA has a convergence faster and has lower error rate.\n\n## Personal Thought\n\nHave tried ADADELTA and SGD. Although for each epoch ADADELTA takes longer time to compute, we just have to input (default value)\n$\\rho = 0.95$ and $\\epsilon = 1e^{-6}$ then it will learn very well. If use SGD, we have to fine tune the learning\nrate and the error rate is often bigger than ADADELTA.\n        &q;,&q;id&q;:&q;1f8f35e7-d29f-48a5-8c44-51eb5ed30492&q;,&q;bannerUrl&q;:&q;/assets/2015061300.png&q;,&q;coverUrl&q;:&q;/assets/2015061300.png&q;,&q;postedAt&q;:&q;2015-06-12T16:00:00.000Z&q;,&q;tags&q;:[&q;machine-learning&q;],&q;title&q;:&q;Paper reading - ADADELTA AN ADAPTIVE LEARNING RATE METHOD&q;,&q;typeCode&q;:1},&q;blogpost-blogHtml&q;:&q;&l;p&g;This &l;a href=\&q;http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf\&q;&g;paper&l;/a&g; was done by Matthew D. Zeiler while he was an intern at Google.&l;/p&g;\n&l;h2&g;Introduction&l;/h2&g;\n&l;p&g;The aim of many machine learning methods is to update a set of parameters \\(x\\) in order to optimize an objective function \\(f(x)\\).\nThis often involves some iterative procedure which applies changes to the parameters, \\(\\Delta{x}\\) at each iteration of the algorithm.\nDenoting the parameters at the t-th iteration as \\(x_t\\), this simple update rule becomes:&l;/p&g;\n&l;p&g;\\[\\Delta{x\\_t} = - \\eta{g\\_t}\\]&l;/p&g;\n&l;ul&g;\n&l;li&g;\\(g_t\\) is the gradient of the parameters at the t-th iteration&l;/li&g;\n&l;li&g;\\(η\\) is a learning rate which controls how large of a step to take in the direction of the negative gradient&l;/li&g;\n&l;/ul&g;\n&l;h2&g;Purpose&l;/h2&g;\n&l;p&g;The idea presented in this paper was derived from ADAGRAD in order to improve upon the two main drawbacks of the method:&l;/p&g;\n&l;ol&g;\n&l;li&g;the continual decay of learning rates throughout training&l;/li&g;\n&l;li&g;the need for a manually selected global learning rate.&l;/li&g;\n&l;/ol&g;\n&l;h2&g;SGD vs ADAGRAD vs ADADELTA&l;/h2&g;\n&l;ul&g;\n&l;li&g;SGD: \\[\\Delta{x\\_t} = \\rho{\\Delta{x\\_{t-1}}} - \\eta{g\\_t} \\]\n&l;ul&g;\n&l;li&g;where \\(\\rho\\) is a constant controlling the decay of the previous parameter updates&l;/li&g;\n&l;/ul&g;\n&l;/li&g;\n&l;li&g;ADAGRAD: \\[\\Delta{x\\_t} = -{ {\\eta} \\over \\sqrt{\\sum\\_{T=1}^t g\\_{T}^2} } \\]&l;/li&g;\n&l;li&g;ADADELTA: \\[\\Delta{x\\_t} = -{ RMS\\[\\Delta{x}\\]\\_{t-1} \\over RMS\\[g\\]\\_t}g\\_t\\]\n\\[RMS[g]\\_t = \\sqrt{E[g^2]\\_t + \\epsilon}\\]\n\\[E[g^2]\\_t = \\rho{E[g^2]\\_{t-1} } + (1-\\rho)g_{t}^2\\]\n&l;ul&g;\n&l;li&g;where a constant \\(\\epsilon\\) is added to better condition the denominator&l;/li&g;\n&l;li&g;where \\(E[g^2]\\_t\\) is expected value of gradient with power 2 at time t&l;/li&g;\n&l;/ul&g;\n&l;/li&g;\n&l;/ul&g;\n&l;h2&g;Result&l;/h2&g;\n&l;p&g;Compared with SGD, ADAGRAD and MOMENTUM, normally ADADELTA has a convergence faster and has lower error rate.&l;/p&g;\n&l;h2&g;Personal Thought&l;/h2&g;\n&l;p&g;Have tried ADADELTA and SGD. Although for each epoch ADADELTA takes longer time to compute, we just have to input (default value)\n\\(\\rho = 0.95\\) and \\(\\epsilon = 1e^{-6}\\) then it will learn very well. If use SGD, we have to fine tune the learning\nrate and the error rate is often bigger than ADADELTA.&l;/p&g;\n&q;,&q;blogpost-showType&q;:3,&q;blogpost-errorMessage&q;:&q;&q;,&q;blogpost-postslug&q;:&q;paper-reading-adadelta-an-adaptive-learning-rate-method&q;,&q;blogpost-userslug&q;:null}</script></body></html>