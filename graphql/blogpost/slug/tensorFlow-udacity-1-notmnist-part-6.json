{"author":{"avatar":"/assets/32x32_avatar.jpg","name":"Liam","tagline":"Make people great again!"},"data":"\n## Summary of 1_notmnist\nBasically 1_notmnist is to learn how to display data in Jupyter Notebook. Besides, it also let us know on sklearn - a python machine library - so that we can then compare with TensorFlow. This is the exact [ipynb file at Tensorflow Github Repo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb).\n\n## Notice\nThis is as a form of sharing and discuss on better way to solve 1_notmnist problem. Do not copy and paste directly as it does not help on improving yourself + the answer is not optimized.\n\nThe entire series of TensorFlow Udacity can be found at [tensorflow-udacity tag](https://www.leliam.com/tag/tensorflow-udacity)\n\n\n## Solving Problem 6\n~~~python\ndef reshape(a):\n    return a.reshape(a.shape[0],a.shape[1]*a.shape[2])\nt = pickle.load(open(\"notMNIST.pickle\", \"r\"))\ny = t['train_labels']\nX = reshape(t['train_dataset']) # reshape it to 2d array\ndel(t) # this should free up more memory spaces\n# choose form 0:10000 because not enough memory for the docker\n# probably a way to do batch learning with scikit-learn\n# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n# http://scikit-learn.org/stable/auto_examples/classification/plot_classification_probability.html\nC = 1.0\nclassifier = LogisticRegression(C=C, penalty='l1')\nclassifier.fit(X[0:10000], y[0:10000])\ny_pred = classifier.predict(X)\nclassif_rate = np.mean(y_pred.ravel() == y.ravel()) * 100\nprint(\"classif_rate for %f \" % (classif_rate))\n# we now see how it is predicted using sample 10001 to 20000, which is not used for training\n# actually should calculate the accuracy in percentage.\nprint(y[10001:20000])\nprint(y_pred[10001:20000])\n~~~\n![png](http://localhost:9000/nghenglim-public/2016042300.png)\n\n## Comment\nThis time we have learnt how to use scikit-learn to do LogisticRegression for notMNIST. As we can see, the classification accuracy is still not bad.\n\nI will expect that tensorflow is either faster and more structured compared to this solution (or google probably will not use this as an example)\n    ","description":"\nBasically 1_notmnist is to learn how to display data in Jupyter Notebook. Besides, it also let us know on sklearn - a python machine library - so that we can then compare with TensorFlow. This is the exact [ipynb file at Tensorflow Github Repo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb).\n    ","id":"410c1b2d-3a6c-4c69-9ddb-cf127fc40315","bannerUrl":"/assets/2016031900.png","coverUrl":"/assets/thumb-150-2016031900.png","postedAt":"2016-04-22T16:00:00.000Z","tags":["machine-learning","tensorflow-udacity"],"title":"TensorFlow Udacity 1_notmnist - Part 6","typeCode":1}